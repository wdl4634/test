RAG（Retrieval Augmented Generation）技术，通过检索与用户输入相关的信息片段，并结合外部知识库来生成更准确、更丰富的回答。解决 LLMs 在处理知识密集型任务时可能遇到的挑战, 如幻觉、知识过时和缺乏透明、可追溯的推理过程等。提供更准确的回答、降低推理成本、实现外部记忆。
RAG 能够让基础模型实现非参数知识更新，无需训练就可以掌握新领域的知识。本次课程选用的茴香豆应用，就应用了 RAG 技术，可以快速、高效的搭建自己的知识领域助手。

  茴香豆怎么部署到微信群, 茴香豆是一个基于 LLM 的**群聊**知识助手，其优势包括：

1. 设计拒答、响应两阶段 pipeline 应对群聊场景，解答问题同时不会消息泛滥。
2. 成本低至 1.5G 显存，无需训练适用各行业。
3. 提供一整套前后端 web、android、算法源码，工业级开源可商用。


茴香豆 Web 版已发布到 [OpenXLab](https://openxlab.org.cn/apps/detail/tpoisonooo/huixiangdou-web)，可以创建自己的知识库、更新正反例、开关网络搜索，聊天测试效果后，集成到飞书/微信群。

- [2024/04] 实现 [RAG 标注 SFT 问答数据和样例](./docs/rag_annotate_sft_data_zh.md)
- [2024/04] 更新 [技术报告](./resource/HuixiangDou.pdf)
- [2024/04] 发布 [web 前后端服务源码](./web) 👍
- [2024/03] 新的[个人微信集成方法](./docs/add_wechat_accessibility_zh.md)和[**预编译 apk**](https://github.com/InternLM/HuixiangDou/releases/download/v0.1.0rc1/huixiangdou-1.0.0.apk) !
- [2024/02] \[实验功能\] [微信群](https://github.com/InternLM/HuixiangDou/blob/main/resource/figures/wechat.jpg) 集成多模态以实现 OCR
 
